{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# ðŸ“¦ Core Libraries\nimport pandas as pd\nimport numpy as np\nimport warnings\n\n# âš™ï¸ ML & Preprocessing Libraries\nfrom cuml.preprocessing import TargetEncoder\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n\n# ðŸ“Š Visualization Libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ðŸ”§ Settings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\nsns.set(style=\"whitegrid\")\n\n# ðŸ“Œ Jupyter Notebook Magic\n%matplotlib inline","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# ðŸ“¥ Load the dataset\ntrain = pd.read_csv(\"/kaggle/input/playground-series-s5e8/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/playground-series-s5e8/test.csv\")\n\noriginal = pd.read_csv(\"/kaggle/input/bank-marketing-dataset-full/bank-full.csv\", sep=';', engine='python')\noriginal['y'] = original['y'].map({'no': 0, 'yes': 1})\n\n# Add a 'dataset' column to track source\ntrain['dataset'] = 'train'\ntest['dataset'] = 'test'\n\noriginal['dataset'] = 'train'\n\n\n\n# Combine train and test datasets for unified preprocessing\ndf = pd.concat([train, test], axis=0).reset_index(drop=True)\n\n# ðŸ§¾ Display dataset shape\nprint(\"Dataset shape:\", df.shape)\n\n# ðŸ‘ï¸ Preview the data\ndf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# original","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Initial Data Inspection","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ“‹ Check column types and non-null counts\ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# âœ… Separate numerical and categorical columns\nnumerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\ncategorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n\nprint(\"Numerical Columns:\", numerical_cols)\nprint(\"Categorical Columns:\", categorical_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ” Check for missing values\nmissing_values = df.isnull().sum()\nmissing_percent = (missing_values / len(df)) * 100\nmissing_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percent})\nmissing_df = missing_df[missing_df['Missing Values'] > 0]\nmissing_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ“Š Descriptive statistics for numerical columns\ndf[numerical_cols].describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ”¢ Unique value counts for categorical columns\nfor col in categorical_cols:\n    print(f\"\\nUnique values in '{col}':\")\n    print(df[col].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming df is your DataFrame\n# ðŸŽ¯ Target Variable Distribution\n# We begin by analyzing the distribution of our target variable, 'y', to see if the dataset is balanced between the two categories (0.0 and 1.0).\n\n# ===== Target Variable Distribution =====\n\nplt.figure(figsize=(6, 4))\nsns.countplot(data=df, x='y', palette='pastel', edgecolor='black')\nplt.title('Distribution of Subscription to Term Deposit (y)', fontsize=14)\nplt.xlabel('Subscribed to Term Deposit (y)', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()\n\n# Display normalized value counts (as proportions)\nprint(\"\\nðŸ“Š Subscription to Term Deposit Value Counts (Proportions):\")\nprint(df['y'].value_counts(normalize=True).round(3))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ“ˆ Distribution of Numerical Features\n# Next, we explore the distribution of the numerical features using histograms. This helps us understand the spread and skewness of the data.\n\n# ===== Visualize Distribution of Numerical Features =====\n\n# List the numerical columns from your dataset\nnum_cols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n\nfor col in num_cols:\n    plt.figure(figsize=(6, 4))\n    sns.histplot(df[col], kde=True, color='skyblue', edgecolor='black')\n    plt.title(f'Distribution of {col}', fontsize=14)\n    plt.xlabel(col, fontsize=12)\n    plt.ylabel('Count', fontsize=12)\n    plt.grid(axis='y', linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.show()\n\n    # Print descriptive statistics\n    print(f'\\nðŸ“Š Descriptive Stats for {col}:\\n')\n    print(df[col].describe(), '\\n' + '-'*40)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Age\n\n- Adults range from **18 up to 95**, with a **mean around 41**.\n- The **middle 50%** lie between **33 and 48** â€” a fairly tight spread around the mean.\n\n## Balance\n\n- **Very heavy rightâ€tail**:  \n  - Maximum â‰ˆ **99,717**  \n  - 75th percentile = **1,390**\n- Some **negative balances** (min â‰ˆ **â€“8,019**), suggesting overdrafts.\n- **Most customers** have **zero or modest balances** (50th percentile = **634**).\n\n## Duration (Call Length)\n\n- **Wide distribution**:\n  - 25% of calls last **less than 91 seconds**\n  - 75th percentile at **359 seconds**\n  - Maximum near **4,918 seconds**\n- Likely **longâ€tail** â€” a few calls last **over an hour**.\n\n## Campaign (Contacts This Campaign)\n\n- Mostly between **1â€“3 contacts** (75% â‰¤ **3**)\n- Some **outliers** with up to **63 contacts**\n\n## Pdays (Days Since Last Contact)\n\n- Most entries are **â€“1** (never previously contacted) â€” even at or below the 75th percentile.\n- **Positive tail** extends up to **871 days**.\n\n## Previous (Number of Contacts Before This Campaign)\n\n- **75%** of customers had **zero prior contacts**\n- A **very small fraction** had many prior contacts â€” **maximum = 200**","metadata":{}},{"cell_type":"code","source":"# ðŸ“¦ Outlier Detection via Boxplots\nplt.figure(figsize=(18, 10))\nfor i, col in enumerate(num_cols):\n    plt.subplot(3, 3, i + 1)\n    sns.boxplot(data=df, y=col, color='#FFA726')\n    plt.title(f\"Boxplot: {col}\")\n    plt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ“Š Distribution of Categorical Features\n\ncat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n\nfor col in cat_cols:\n    plt.figure(figsize=(10, 4))\n    sns.countplot(\n        data=df,\n        x=col,\n        order=df[col].value_counts().index,\n        palette='Set2',\n        edgecolor='black'\n    )\n    plt.title(f'{col} Distribution', fontsize=14)\n    plt.xlabel(col, fontsize=12)\n    plt.ylabel('Count', fontsize=12)\n    plt.xticks(rotation=45, ha='right')\n    plt.grid(axis='y', linestyle='--', alpha=0.5)\n    plt.tight_layout()\n    plt.show()\n\n    # ðŸ§® Print Category Proportions\n    print(f'\\nðŸ“Š Proportion of Each Category in \"{col}\":\\n')\n    print(df[col].value_counts(normalize=True).round(3), '\\n' + '-'*40)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸŽ¨ Categorical Feature Distributions by Subscription Status (y) - Custom Colors\n\ncols_to_plot = ['housing', 'loan', 'contact', 'poutcome']\ncustom_palette = ['#1F77B4', '#FF7F0E']  # Blue for 0, Orange for 1\n\nfor col in cols_to_plot:\n    plt.figure(figsize=(6, 4))\n    sns.countplot(\n        data=df,\n        x=col,\n        hue='y',\n        palette=custom_palette,\n        edgecolor='black'\n    )\n    plt.title(f'Distribution of {col} by Subscription (y)', fontsize=14)\n    plt.xlabel(f'{col}', fontsize=12)\n    plt.ylabel('Count', fontsize=12)\n    plt.xticks(rotation=45, ha='right')\n    plt.legend(title='Subscribed (y)', labels=['No (0)', 'Yes (1)'])\n    plt.grid(axis='y', linestyle='--', alpha=0.4)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ”— Correlation Between Numerical Features\n\nplt.figure(figsize=(10, 6))\nsns.heatmap(\n    df[num_cols].corr(),\n    annot=True,\n    cmap='coolwarm',\n    fmt=\".2f\",\n    linewidths=0.5,\n    linecolor='white',\n    annot_kws={\"size\": 10},\n    cbar_kws={\"shrink\": 0.8}\n)\nplt.title(\"Correlation Between Numerical Features\", fontsize=14)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ§  Feature vs Target Relationship (Numerical Features by Subscription)\n\nplt.figure(figsize=(18, 10))\n\nfor i, col in enumerate(num_cols):\n    plt.subplot(2, 4, i + 1)\n    sns.boxplot(\n        data=df,\n        x='y',\n        y=col,\n        palette=['#1F77B4', '#FF7F0E'],  # Blue for 0, Orange for 1\n        linewidth=1.2,\n        fliersize=4\n    )\n    plt.title(f'{col} by Subscription', fontsize=14, fontweight='semibold', color='#2E4057')\n    plt.xlabel('Subscribed (y)', fontsize=12)\n    plt.ylabel(col, fontsize=12)\n    plt.grid(axis='y', linestyle='--', alpha=0.4)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"########\n\n# Log-transform balance and duration\ndf['log_balance']  = np.log1p(df['balance'] - df['balance'].min() + 1)\ndf['log_duration'] = np.log1p(df['duration'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Handling Missing Values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ‘€ Count \"unknown\" values (treated as missing in many cases)\nfor col in df.columns:\n    if df[col].dtype == 'object':\n        print(f'{col} â†’ unknowns: {df[col].isin([\"unknown\"]).sum()}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encoding\n\nbinary_map = {'yes': 1, 'no': 0}\ndf['default'] = df['default'].map(binary_map)\ndf['housing'] = df['housing'].map(binary_map)\ndf['loan'] = df['loan'].map(binary_map)\n\n# df['y'] = df['y'].astype(int)  # 0 or 1\n\nmulti_cat_cols = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\ndf = pd.get_dummies(df, columns=multi_cat_cols, drop_first=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ðŸ§ª Separate Train and Test Sets\ntrain_df = df[df['dataset'] == 'train'].drop(columns=['dataset'], errors='ignore')\ntest_df  = df[df['dataset'] == 'test'].drop(columns=['dataset'], errors='ignore')\n\n# ðŸ§¹ Drop Unnecessary Columns\ntrain_df = train_df.drop(columns=['id', 'balance', 'duration'], errors='ignore')  # duration is a data leak\ntest_df  = test_df.drop(columns=['y', 'balance', 'duration'], errors='ignore')\n\n# ðŸŽ¯ Separate Features and Target\nX = train_df.drop('y', axis=1)\n# y = train_df['y'].astype(int)  # ensure target is integer\ny = train_df['y']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Machine Learning","metadata":{}},{"cell_type":"code","source":"# # Modeling with target encoding\n\n# # Parameters\n# n_splits = 10\n# random_state = 42\n\n# # Containers for metrics\n# catboost_oof_preds = np.zeros(len(X))\n# xgb_oof_preds = np.zeros(len(X))\n\n# catboost_auc_scores = []\n# xgb_auc_scores = []\n\n# catboost_feature_importances = []\n# xgb_feature_importances = []\n# feature_names = X.columns\n\n# # # Initialize K-Fold\n# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n\n# # Specify categorical columns to encode\n# categorical_cols = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n# # categorical_cols = ['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n# #        'contact', 'day', 'month', 'campaign', 'pdays', 'previous', 'poutcome',\n# #        'log_balance', 'log_duration']\n# # Add placeholders for encoded feature names\n# for col in categorical_cols:\n#     X[f'TE_{col}'] = np.nan\n\n# # Begin Cross-Validation\n# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n#     print(f\"\\n--- Fold {fold} ---\")\n\n#     X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n#     # --- Target Encoding ---\n#     for col in categorical_cols:\n#         te = TargetEncoder(n_folds=25, smooth=20, split_method='random', stat='mean')\n#         X_train[f'TE_{col}'] = te.fit_transform(X_train[col], y_train)\n#         X_val[f'TE_{col}'] = te.transform(X_val[col])\n    \n#     # Drop original categorical columns\n#     X_train_enc = X_train.drop(columns=categorical_cols)\n#     X_val_enc = X_val.drop(columns=categorical_cols)\n\n#     feature_names = X_train_enc.columns  # update\n\n#     # ----- CatBoost -----\n#     cat_model = CatBoostClassifier(\n#         iterations=1000,\n#         learning_rate=0.05,\n#         depth=6,\n#         eval_metric='AUC',\n#         random_seed=random_state,\n#         early_stopping_rounds=50,\n#         verbose=100,\n#         task_type='GPU',\n#         devices='0'\n#     )\n#     cat_model.fit(X_train_enc, y_train, eval_set=(X_val_enc, y_val), use_best_model=True)\n#     val_pred_cat = cat_model.predict_proba(X_val_enc)[:, 1]\n#     auc_cat = roc_auc_score(y_val, val_pred_cat)\n#     catboost_auc_scores.append(auc_cat)\n#     catboost_oof_preds[val_idx] = val_pred_cat\n#     catboost_feature_importances.append(cat_model.get_feature_importance())\n#     print(f\"CatBoost Fold {fold} AUC: {auc_cat:.4f}\")\n\n#     # ----- XGBoost -----\n#     xgb_model = xgb.XGBClassifier(\n#         max_depth=13,\n#         learning_rate=0.01036808915308291,\n#         min_child_weight=7,\n#         subsample=0.4406,\n#         colsample_bytree=0.8033,\n#         gamma=2.46,\n#         reg_alpha=2.14,\n#         reg_lambda=1.57,\n#         n_estimators=50000,\n#         eval_metric='auc',\n#         use_label_encoder=False,\n#         random_state=random_state,\n#         verbosity=1,\n#         early_stopping_rounds=50,\n#         tree_method='gpu_hist',\n#         predictor='gpu_predictor'\n#     )\n#     xgb_model.fit(X_train_enc, y_train, eval_set=[(X_val_enc, y_val)], verbose=100)\n#     val_pred_xgb = xgb_model.predict_proba(X_val_enc)[:, 1]\n#     auc_xgb = roc_auc_score(y_val, val_pred_xgb)\n#     xgb_auc_scores.append(auc_xgb)\n#     xgb_oof_preds[val_idx] = val_pred_xgb\n#     xgb_feature_importances.append(xgb_model.feature_importances_)\n#     print(f\"XGBoost Fold {fold} AUC: {auc_xgb:.4f}\")\n\n# # Convert lists to arrays\n# catboost_feature_importances = np.array(catboost_feature_importances)\n# xgb_feature_importances = np.array(xgb_feature_importances)\n\n# # Average feature importances across folds\n# avg_catboost_importance = np.mean(catboost_feature_importances, axis=0)\n# avg_xgb_importance = np.mean(xgb_feature_importances, axis=0)\n\n# # Create DataFrames for easier interpretation\n# catboost_importance_df = pd.DataFrame({\n#     'Feature': feature_names,\n#     'Importance': avg_catboost_importance\n# }).sort_values(by='Importance', ascending=False)\n\n# xgb_importance_df = pd.DataFrame({\n#     'Feature': feature_names,\n#     'Importance': avg_xgb_importance\n# }).sort_values(by='Importance', ascending=False)\n\n# print(\"\\n=== CatBoost Feature Importance ===\")\n# print(catboost_importance_df)\n\n# print(\"\\n=== XGBoost Feature Importance ===\")\n# print(xgb_importance_df)\n\n    \n# # Summary\n# print(\"\\n=== Summary ===\")\n# print(f\"CatBoost Mean AUC: {np.mean(catboost_auc_scores):.4f} Â± {np.std(catboost_auc_scores):.4f}\")\n# print(f\"XGBoost Mean AUC: {np.mean(xgb_auc_scores):.4f} Â± {np.std(xgb_auc_scores):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Modeling without target encoding\n\n# # Parameters\n# n_splits = 10\n# random_state = 42\n\n# # Initialize K-Fold\n# skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n# # Containers for metrics\n# catboost_oof_preds = np.zeros(len(X))\n# xgb_oof_preds = np.zeros(len(X))\n\n# catboost_auc_scores = []\n# xgb_auc_scores = []\n\n# catboost_feature_importances = []\n# xgb_feature_importances = []\n# feature_names = X.columns\n\n\n# for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n#     print(f\"\\n--- Fold {fold} ---\")\n\n#     X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    \n#     # ----- CatBoost with GPU -----\n#     cat_model = CatBoostClassifier(\n#         iterations=1000,\n#         learning_rate=0.05,\n#         depth=6,\n#         eval_metric='AUC',\n#         random_seed=random_state,\n#         early_stopping_rounds=50,\n#         verbose=100,\n#         task_type='GPU',\n#         devices='0'\n#     )\n#     cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n#     val_pred_cat = cat_model.predict_proba(X_val)[:, 1]\n#     auc_cat = roc_auc_score(y_val, val_pred_cat)\n#     catboost_auc_scores.append(auc_cat)\n#     catboost_oof_preds[val_idx] = val_pred_cat\n#     catboost_feature_importances.append(cat_model.get_feature_importance())\n#     print(f\"CatBoost Fold {fold} AUC: {auc_cat:.4f}\")\n    \n#     # ----- XGBoost with GPU -----\n#     xgb_model = xgb.XGBClassifier(\n#         max_depth=13,\n#         learning_rate=0.01036808915308291,\n#         min_child_weight=7,\n#         subsample=0.4406011562109482,\n#         colsample_bytree=0.8033679369123714,\n#         gamma=2.4652180617514747,\n#         reg_alpha=2.1421895943084053,\n#         reg_lambda=1.5758614095439158,\n#         n_estimators=50000,\n#         eval_metric='auc',\n#         use_label_encoder=False,\n#         random_state=random_state,\n#         verbosity=1,\n#         early_stopping_rounds=50,\n#         tree_method='gpu_hist',\n#         predictor='gpu_predictor'\n#         )\n#     # After XGBoost model fitting\n#     xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n#     val_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n#     auc_xgb = roc_auc_score(y_val, val_pred_xgb)\n#     xgb_auc_scores.append(auc_xgb)\n#     xgb_oof_preds[val_idx] = val_pred_xgb\n#     xgb_feature_importances.append(xgb_model.feature_importances_)\n#     print(f\"XGBoost Fold {fold} AUC: {auc_xgb:.4f}\")\n\n\n\n# # Convert lists to arrays\n# catboost_feature_importances = np.array(catboost_feature_importances)\n# xgb_feature_importances = np.array(xgb_feature_importances)\n\n# # Average feature importances across folds\n# avg_catboost_importance = np.mean(catboost_feature_importances, axis=0)\n# avg_xgb_importance = np.mean(xgb_feature_importances, axis=0)\n\n# # Create DataFrames for easier interpretation\n# catboost_importance_df = pd.DataFrame({\n#     'Feature': feature_names,\n#     'Importance': avg_catboost_importance\n# }).sort_values(by='Importance', ascending=False)\n\n# xgb_importance_df = pd.DataFrame({\n#     'Feature': feature_names,\n#     'Importance': avg_xgb_importance\n# }).sort_values(by='Importance', ascending=False)\n\n# print(\"\\n=== CatBoost Feature Importance ===\")\n# print(catboost_importance_df)\n\n# print(\"\\n=== XGBoost Feature Importance ===\")\n# print(xgb_importance_df)\n\n    \n# # Summary\n# print(\"\\n=== Summary ===\")\n# print(f\"CatBoost Mean AUC: {np.mean(catboost_auc_scores):.4f} Â± {np.std(catboost_auc_scores):.4f}\")\n# print(f\"XGBoost Mean AUC: {np.mean(xgb_auc_scores):.4f} Â± {np.std(xgb_auc_scores):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modeling without target encoding\n\n# Parameters\nn_splits = 7\nrandom_state = 42\n\n# Initialize K-Fold\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n\n# Containers for metrics\ncatboost_oof_preds = np.zeros(len(X))\nxgb_oof_preds      = np.zeros(len(X))\nlgbm_oof_preds     = np.zeros(len(X))\n\ncatboost_auc_scores = []\nxgb_auc_scores      = []\nlgbm_auc_scores     = []\n\ncatboost_feature_importances = []\nxgb_feature_importances      = []\nlgbm_feature_importances     = []\n\nfeature_names = X.columns\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n    print(f\"\\n--- Fold {fold} ---\")\n\n    X_train, X_val = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n    # ----- CatBoost with GPU -----\n    cat_model = CatBoostClassifier(\n        iterations=1000,\n        learning_rate=0.05,\n        depth=6,\n        eval_metric='AUC',\n        random_seed=random_state,\n        early_stopping_rounds=50,\n        verbose=100,\n        task_type='GPU',\n        devices='0'\n    )\n    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n    val_pred_cat = cat_model.predict_proba(X_val)[:, 1]\n    auc_cat = roc_auc_score(y_val, val_pred_cat)\n    catboost_auc_scores.append(auc_cat)\n    catboost_oof_preds[val_idx] = val_pred_cat\n    catboost_feature_importances.append(cat_model.get_feature_importance())\n    print(f\"CatBoost Fold {fold} AUC: {auc_cat:.4f}\")\n\n    # ----- XGBoost with GPU -----\n    import xgboost as xgb\n\n    xgb_params = {\n        'n_estimators': 8000,         \n        'max_leaves': 127,            \n        'min_child_weight': 1.5,     \n        'max_depth': 0,               \n        'grow_policy': 'lossguide',   \n        'learning_rate': 0.008,      \n        'tree_method': 'hist',        \n        'subsample': 0.85,            \n        'colsample_bylevel': 0.7,     \n        'colsample_bytree': 0.75,       \n        'colsample_bynode': 0.85,     \n        'sampling_method': 'gradient_based',  \n        'reg_alpha': 2.5,             \n        'reg_lambda': 0.8,            \n        'enable_categorical': True,    \n        'max_cat_to_onehot': 1,       \n        'device': 'cuda',            \n        'n_jobs': -1,                 \n        'random_state': 42,     \n        'verbosity': 0,               \n        'objective': 'binary:logistic',\n        # 'eval_metric': 'auc'\n    }\n\n    xgb_model = xgb.XGBClassifier(**xgb_params)\n\n    xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=100)\n    val_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n    auc_xgb = roc_auc_score(y_val, val_pred_xgb)\n    xgb_auc_scores.append(auc_xgb)\n    xgb_oof_preds[val_idx] = val_pred_xgb\n    xgb_feature_importances.append(xgb_model.feature_importances_)\n    print(f\"XGBoost Fold {fold} AUC: {auc_xgb:.4f}\")\n\n    # ----- LightGBM with GPU -----\n    lgbm_model = lgb.LGBMClassifier(\n        random_state=42,\n        verbosity=-1,\n        n_estimators=25000,\n        learning_rate=0.05,\n        min_child_samples=9,\n        subsample=0.8,\n        colsample_bytree=0.5,\n        num_leaves=100,\n        max_depth=10,\n        max_bin=3600,\n        reg_alpha=0.79,\n        reg_lambda=3,\n    )\n    lgbm_model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        eval_metric='auc',\n        callbacks=[\n            lgb.early_stopping(stopping_rounds=50),\n            lgb.log_evaluation(period=100)\n        ]\n    )\n    val_pred_lgbm = lgbm_model.predict_proba(X_val)[:, 1]\n    auc_lgbm = roc_auc_score(y_val, val_pred_lgbm)\n    lgbm_auc_scores.append(auc_lgbm)\n    lgbm_oof_preds[val_idx] = val_pred_lgbm\n    lgbm_feature_importances.append(lgbm_model.feature_importances_)\n    print(f\"LightGBM Fold {fold} AUC: {auc_lgbm:.4f}\")\n\n# Convert lists to arrays\ncatboost_feature_importances = np.array(catboost_feature_importances)\nxgb_feature_importances      = np.array(xgb_feature_importances)\nlgbm_feature_importances     = np.array(lgbm_feature_importances)\n\n# Average feature importances across folds\navg_catboost_importance = np.mean(catboost_feature_importances, axis=0)\navg_xgb_importance      = np.mean(xgb_feature_importances, axis=0)\navg_lgbm_importance     = np.mean(lgbm_feature_importances, axis=0)\n\n# Create DataFrames for easier interpretation\ncatboost_importance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': avg_catboost_importance\n}).sort_values(by='Importance', ascending=False)\n\nxgb_importance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': avg_xgb_importance\n}).sort_values(by='Importance', ascending=False)\n\nlgbm_importance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': avg_lgbm_importance\n}).sort_values(by='Importance', ascending=False)\n\nprint(\"\\n=== CatBoost Feature Importance ===\")\nprint(catboost_importance_df)\n\nprint(\"\\n=== XGBoost Feature Importance ===\")\nprint(xgb_importance_df)\n\nprint(\"\\n=== LightGBM Feature Importance ===\")\nprint(lgbm_importance_df)\n\n# Summary\nprint(\"\\n=== Summary ===\")\nprint(f\"CatBoost Mean AUC:   {np.mean(catboost_auc_scores):.4f} Â± {np.std(catboost_auc_scores):.4f}\")\nprint(f\"XGBoost Mean AUC:     {np.mean(xgb_auc_scores):.4f} Â± {np.std(xgb_auc_scores):.4f}\")\nprint(f\"LightGBM Mean AUC:    {np.mean(lgbm_auc_scores):.4f} Â± {np.std(lgbm_auc_scores):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---- Plot Top 20 Features ----\n\n# CatBoost\nplt.figure(figsize=(10, 8))\ncatboost_importance_df.head(20).plot.barh(\n    x='Feature', y='Importance',\n    title='CatBoost Feature Importance (Top 20)',\n    legend=False, ax=plt.gca()\n)\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n# XGBoost\nplt.figure(figsize=(10, 8))\nxgb_importance_df.head(20).plot.barh(\n    x='Feature', y='Importance',\n    title='XGBoost Feature Importance (Top 20)',\n    legend=False, ax=plt.gca()\n)\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()\n\n# LightGBM\nplt.figure(figsize=(10, 8))\nlgbm_importance_df.head(20).plot.barh(\n    x='Feature', y='Importance',\n    title='LightGBM Feature Importance (Top 20)',\n    legend=False, ax=plt.gca()\n)\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Prepare test features by dropping the 'id' column if it exists\ntest_features = test_df.drop(columns=['id'], errors='ignore')\n\n# # Apply TE on test set using last fold's encoder (or average across folds if more precise)\n# for col in categorical_cols:\n#     te = TargetEncoder(n_folds=25, smooth=20, split_method='random', stat='mean')\n#     te.fit(X[col], y)  # fit on full training data\n#     test_features[f'TE_{col}'] = te.transform(test_features[col])\n#     test_features = test_features.drop(columns=col)\n\n# # Predict probabilities on test set\n# # test_pred_prob = cat_model.predict_proba(test_features)[:, 1]\n# # test_pred_prob = xgb_model.predict_proba(test_features)[:, 1]\n# test_pred_prob = lgbm_model.predict_proba(test_features)[:, 1]\n\n\n# --- Assumes you have already trained your models: cat_model, xgb_model, lgbm_model ---\n# --- And you have your test_features ready ---\n\n# 1. Get predicted probabilities from each model\ncat_pred_prob = cat_model.predict_proba(test_features)[:, 1]\nxgb_pred_prob = xgb_model.predict_proba(test_features)[:, 1]\nlgbm_pred_prob = lgbm_model.predict_proba(test_features)[:, 1]\n\n# 2. Ensemble the predictions by averaging them\nensemble_pred_prob = (cat_pred_prob + xgb_pred_prob + lgbm_pred_prob) / 3\n\ntest_pred_prob = ensemble_pred_prob\n\n# Now 'ensemble_pred_prob' holds your final ensembled predictions.\n# You can use it to calculate metrics or make final classifications.\n# For example, to convert to class labels with a 0.5 threshold:\n# ensemble_pred_class = (ensemble_pred_prob >= 0.5).astype(int)\n\n\n# Assuming you have an ID column saved before dropping\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'y': test_pred_prob\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission saved!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# THANKS\n# It will be updated\n# Please Upvote if you like it","metadata":{}}]}